{
    "version": "https://jsonfeed.org/version/1",
    "title": "Hexo • All posts by \"hadoop\" category",
    "description": "",
    "home_page_url": "http://book.asmyun.com",
    "items": [
        {
            "id": "http://book.asmyun.com/2020/12/29/computer-science/hadoop/hadoop-install/",
            "url": "http://book.asmyun.com/2020/12/29/computer-science/hadoop/hadoop-install/",
            "title": "hadoop_install",
            "date_published": "2020-12-29T06:01:41.000Z",
            "content_html": "<ul>\n<li><a href=\"#hadoop%E4%BB%8B%E7%BB%8D\">hadoop介绍</a></li>\n<li><a href=\"#%E8%AE%B0%E5%BD%95%E9%9B%86%E8%BF%9E%E6%8E%A5\">记录集连接</a></li>\n<li><a href=\"#%E8%AE%B0%E5%BD%95%E5%85%B3%E8%81%94\">记录关联</a></li>\n</ul>\n<ul>\n<li><a href=\"#\">Post not found: kettle-install 安装kettle</a></li>\n<li><a href=\"#\">Post not found: kettle-one 编写第一个作业</a></li>\n<li><a href=\"#\">Post not found: kettle-control 组件介绍</a></li>\n<li><a href=\"#\">Post not found: kettle-demo kettle示例</a>\n\n</li>\n</ul>\n<h4 id=\"hadoop介绍\"><a href=\"#hadoop介绍\" class=\"headerlink\" title=\"hadoop介绍\"></a>hadoop介绍</h4><h4 id=\"hadoop下载\"><a href=\"#hadoop下载\" class=\"headerlink\" title=\"hadoop下载\"></a>hadoop下载</h4><h4 id=\"hadoop安装\"><a href=\"#hadoop安装\" class=\"headerlink\" title=\"hadoop安装\"></a>hadoop安装</h4><h4 id=\"hadoop配置\"><a href=\"#hadoop配置\" class=\"headerlink\" title=\"hadoop配置\"></a>hadoop配置</h4><h4 id=\"hadoop异常解决\"><a href=\"#hadoop异常解决\" class=\"headerlink\" title=\"hadoop异常解决\"></a>hadoop异常解决</h4><h5 id=\"ERROR-but-there-is-no-HDFS-NAMENODE-USER-defined-Aborting-operation\"><a href=\"#ERROR-but-there-is-no-HDFS-NAMENODE-USER-defined-Aborting-operation\" class=\"headerlink\" title=\"ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\"></a>ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.</h5><p>The root cause of this problem,</p>\n<p>hadoop install for different user and you start yarn service for different user. OR<br>in hadoop config’s hadoop-env.sh specified HDFS_NAMENODE_USER and HDFS_DATANODE_USER user is something else.<br>Hence we need to correct and make it consistent at every place. So a simple solution of this problem is to edit your hadoop-env.sh file and add the user-name for which you want to start the yarn service. So go ahead and edit $HADOOP_HOME/etc/hadoop/hadoop-env.sh by adding the following lines</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export HDFS_NAMENODE_USER=root</span><br><span class=\"line\">export HDFS_DATANODE_USER=root</span><br><span class=\"line\">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class=\"line\">export YARN_RESOURCEMANAGER_USER=root</span><br><span class=\"line\">export YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>\n<h5 id=\"ERROR-JAVA-HOME-is-not-set-and-could-not-be-found\"><a href=\"#ERROR-JAVA-HOME-is-not-set-and-could-not-be-found\" class=\"headerlink\" title=\"ERROR: JAVA_HOME is not set and could not be found.\"></a>ERROR: JAVA_HOME is not set and could not be found.</h5><p>没有配置好java环境变量<br>第一种临时修改环境变量<br><code>export JAVA_HOME=/usr/java/jdk1.6.0_45</code><br>第二种修改hadoop JAVA_HOME<br><code>cd $HADOOP_HOME/etc/hadoop</code><br><code>vim hadoop-env.sh</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Many of the options here are built from the perspective that users</span></span><br><span class=\"line\"><span class=\"comment\"># may want to provide OVERWRITING values on the command line.</span></span><br><span class=\"line\"><span class=\"comment\"># For example:</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#  JAVA_HOME=/usr/java/testing hdfs dfs -ls</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Therefore, the vast majority (BUT NOT ALL!) of these defaults</span></span><br><span class=\"line\"><span class=\"comment\"># are configured for substitution and not append.  If append</span></span><br><span class=\"line\"><span class=\"comment\"># is preferable, modify this file accordingly.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###</span></span><br><span class=\"line\"><span class=\"comment\"># Generic settings for HADOOP</span></span><br><span class=\"line\"><span class=\"comment\">###</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Technically, the only required environment variable is JAVA_HOME.</span></span><br><span class=\"line\"><span class=\"comment\"># All others are optional.  However, the defaults are probably not</span></span><br><span class=\"line\"><span class=\"comment\"># preferred.  Many sites configure these options outside of Hadoop,</span></span><br><span class=\"line\"><span class=\"comment\"># such as in /etc/profile.d</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The java implementation to use. By default, this environment</span></span><br><span class=\"line\"><span class=\"comment\"># variable is REQUIRED on ALL platforms except OS X!</span></span><br><span class=\"line\">export JAVA_HOME=/root/java/jdk1<span class=\"number\">.8</span><span class=\"number\">.0_271</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Location of Hadoop.  By default, Hadoop will attempt to determine</span></span><br><span class=\"line\"><span class=\"comment\"># this location based upon its execution path.</span></span><br><span class=\"line\"><span class=\"comment\"># export HADOOP_HOME=</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Location of Hadoop&#x27;s configuration information.  i.e., where this</span></span><br><span class=\"line\"><span class=\"comment\"># file is living. If this is not defined, Hadoop will attempt to</span></span><br><span class=\"line\"><span class=\"comment\"># locate it based upon its execution path.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># <span class=\"doctag\">NOTE:</span> It is recommend that this variable not be set here but in</span></span><br><span class=\"line\"><span class=\"comment\"># /etc/profile.d or equivalent.  Some options (such as</span></span><br><span class=\"line\"><span class=\"comment\"># --config) may react strangely otherwise.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum amount of heap to use (Java -Xmx).  If no unit</span></span><br><span class=\"line\"><span class=\"comment\"># is provided, it will be converted to MB.  Daemons will</span></span><br><span class=\"line\"><span class=\"comment\"># prefer any Xmx setting in their respective _OPT variable.</span></span><br><span class=\"line\"><span class=\"comment\"># There is no default; the JVM will autoscale based upon machine</span></span><br><span class=\"line\"><span class=\"comment\"># memory size.</span></span><br><span class=\"line\"><span class=\"comment\"># export HADOOP_HEAPSIZE_MAX=</span></span><br></pre></td></tr></table></figure>\n\n<h5 id=\"Permission-denied-publickey-gssapi-keyex-gssapi-with-mic-password\"><a href=\"#Permission-denied-publickey-gssapi-keyex-gssapi-with-mic-password\" class=\"headerlink\" title=\"Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\"></a>Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).</h5>",
            "tags": []
        }
    ]
}